---
title: Building a Local YouTube Assistant with LLM and Vector Databases
description: Learn how to build a smart local YouTube assistant using LangChain, Pinecone, and Ollama-powered LLMs.
tags: [YouTube, LangChain, LLM, Pinecone, Ollama, AI, Node.js]
image: /images/blog/youtube-llm.png
date: 2023-03-22
---

Have you ever wished for a smart YouTube assistant that runs locally, understands your queries, and fetches the right insights instantly? Well, you‚Äôre in the right place! üöÄ

> **Note**: This blog assumes you know basic JavaScript. The required code is in the associated [GitHub repo](https://github.com/vetri15/langchain_demo).

## Table of Contents

-   [Overview](#Overview)
-   [Prerequisites](#Prerequisites)
-   [Walkthrough](#Walkthrough)

---

## Overview

The following steps happen in sequence once the user inputs his YouTube link and the question.

-   The YouTube transcript is fetched using the Langchain library.
-   The fetched transcript is broken into text chunks and indexed in Pinecone DB.
-   From the Pinecone DB, the chunks relevant to the question are retrieved.
-   The relevant chunks and the question are sent to the locally running LLM.
-   The LLM does its magic‚ú® and gives the output to the user.

---

## Prerequisites

To run this project you need 2 things apart from the GitHub repo.

**1. Pinecone API key**

You can sign up for a free API key using this link [Pinecone DB](https://www.pinecone.io/)

**2. A local running LLM**

For this we use Ollama, It is an open-source tool that allows users to easily run large language models (LLMs) locally on their computers.
You can download ollama using the [link‚¨áÔ∏è](https://ollama.com/download/OllamaSetup.exe). To learn more about ollama visit the GitHub [link](https://github.com/ollama/ollama)

---

## Walkthrough

Once you have got the API key and installed ollama, go through the below steps.

1. Clone the [GitHub repo](https://github.com/vetri15/langchain_demo) and install node packages.

```bash
git clone https://github.com/vetri15/langchain_demo
cd langchain_demo
npm install
```

2. Rename the .env.example file and set up your environment variables.

```bash
Rename-Item -Path .env.example -NewName .env
Set-Content .env 'PINECONE_API_KEY=your-api-key'
```

3. next run your local LLM using ollama. we will use the [deepseek-r1 model](https://ollama.com/library/deepseek-r1).
There are various parameters available, the higher the parameters the better. I could run up to 14B parameter model using my Nvidia RTX 2050 Mobile GPU paired with my Ryzen 7 processor. You may choose between 8B, 14B, and 32B models based on your PC.
The below code will download and run the corresponding ollama model. Ollama will take some time to install. since DeepSeek models are a few GBs.

```bash
ollama run deepseek-r1:14b
```

4. Once Deepseek is running. run the node.js application using the below code.

```bash
node index.js
```

5. Now paste the [YouTube link](https://www.youtube.com/watch?v=JKBk_Kfucs4) and ask questions about the video.

---

Voila! You now have a locally running YouTube assistant.

If you have any queries, feel free to comment.‚ò∫Ô∏è